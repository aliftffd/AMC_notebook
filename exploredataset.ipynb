{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5613e6e2-07b8-47e3-a7aa-3438918e28a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import h5py\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import torch \n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe2ea5a8-bf68-4fdb-aa2d-6e0bb7d27aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eddcc62-cf52-4127-a5f6-940b171d85cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update this path if needed\n",
    "file_path = '/home/lipplopp/Documents/research/notebook/notebook_1/dataset/radioml2018/versions/2/GOLD_XYZ_OSC.0001_1024.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bac790c6-1457-4b5a-b3cb-fff9e846e287",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels=2\n",
    "batch_size=32\n",
    "# Number of frames per snr/modulation combination for train,valid and test data\n",
    "nf_train = 1024\n",
    "nf_valid = 512\n",
    "nf_test = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f7af59-74bd-483c-b653-793b5b3ff5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_split(data,\n",
    "                   modulations_classes,\n",
    "                   modulations,snrs,\n",
    "                   target_modulations,\n",
    "                   mode,\n",
    "                   target_snrs,train_proportion=0.7,\n",
    "                   valid_proportion=0.2,\n",
    "                   test_proportion=0.1,\n",
    "                   seed=48):\n",
    "    np.random.seed(seed)\n",
    "    train_split_index = int(train_proportion*4096)\n",
    "    valid_split_index = int((valid_proportion+train_proportion)*4096)\n",
    "    test_split_index = int((test_proportion+valid_proportion+train_proportion)*4096)\n",
    "    X_output=[]\n",
    "    Y_output=[]\n",
    "    Z_output=[]\n",
    "\n",
    "    target_modulation_indices = [modulations_classes.index(modu) for modu in target_modulations]\n",
    "    \n",
    "    for modu in  target_modulation_indices:       \n",
    "        for snr in target_snrs:\n",
    "            snr_modu_indices = np.where((modulations==modu) & (snrs==snr))[0]\n",
    "\n",
    "            np.random.shuffle(snr_modu_indices)\n",
    "            train, valid, test, remaining = np.split(snr_modu_indices, [train_split_index,valid_split_index,test_split_index])\n",
    "            if mode=='train':\n",
    "                X_output.append(data[np.sort(train)])\n",
    "                Y_output.append(modulations[np.sort(train)])\n",
    "                Z_output.append(snrs[np.sort(train)])\n",
    "            elif mode=='valid':\n",
    "                X_output.append(data[np.sort(valid)])\n",
    "                Y_output.append(modulations[np.sort(valid)])\n",
    "                Z_output.append(snrs[np.sort(valid)])\n",
    "            elif mode =='test':\n",
    "                X_output.append(data[np.sort(test)])\n",
    "                Y_output.append(modulations[np.sort(test)])\n",
    "                Z_output.append(snrs[np.sort(test)])\n",
    "            else:\n",
    "                raise ValueError(f'unknown mode: {mode}. Valid modes are train, valid and test') \n",
    "    X_array = np.vstack(X_output)\n",
    "    Y_array = np.concatenate(Y_output)\n",
    "    Z_array = np.concatenate(Z_output)\n",
    "    for index,value in enumerate(np.unique(np.copy(Y_array))):\n",
    "        Y_array[Y_array==value]=index\n",
    "    return X_array, Y_array, Z_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1533e5-95fa-4c10-bf56-3fa1e9aee59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadioML18Dataset(Dataset):\n",
    "    def __init__(self, mode: str,seed=48,):\n",
    "        super(RadioML18Dataset, self).__init__()\n",
    "        \n",
    "        # load data\n",
    "        hdf5_file = h5py.File(\"/home/lipplopp/Documents/research/notebook/notebook_1/dataset/radioml2018/versions/2/GOLD_XYZ_OSC.0001_1024.hdf5\",  'r')\n",
    "        self.modulation_classes = json.load(open(\"/home/lipplopp/Documents/research/notebook/notebook_1/dataset/radioml2018/versions/2/classes-fixed.json\", 'r'))\n",
    "        self.X = hdf5_file['X']\n",
    "        self.Y = np.argmax(hdf5_file['Y'], axis=1)\n",
    "        self.Z = hdf5_file['Z'][:, 0]\n",
    "        \n",
    "        train_proportion=(24*26*nf_train)/self.X.shape[0]\n",
    "        valid_proportion=(24*26*nf_valid)/self.X.shape[0]\n",
    "        test_proportion=(24*26*nf_test)/self.X.shape[0]\n",
    "        \n",
    "        \"\"\"target_modulations =['OOK', '4ASK', 'BPSK', 'QPSK', '8PSK',\n",
    "        '16QAM', 'AM-SSB-SC', 'AM-DSB-SC', 'FM', 'GMSK','OQPSK']target \n",
    "        modulation class and snr\"\"\"   \n",
    "\n",
    "        # in this line i could change it the target modulation \n",
    "        self.target_modulations =['OOK', '4ASK', 'BPSK', 'QPSK', '8PSK',\n",
    "        '16QAM', 'AM-SSB-SC', 'AM-DSB-SC', 'FM', 'GMSK','OQPSK']\n",
    "\n",
    "        self.target_snrs = np.unique(self.Z)\n",
    "        \n",
    "        self.X_data, self.Y_data, self.Z_data = dataset_split(\n",
    "                                                                  data = self.X,\n",
    "                                                                  modulations_classes = self.modulation_classes,\n",
    "                                                                  modulations = self.Y,\n",
    "                                                                  snrs = self.Z,\n",
    "                                                                  mode = mode,\n",
    "                                                                  train_proportion = train_proportion,\n",
    "                                                                  valid_proportion = valid_proportion,\n",
    "                                                                  test_proportion = test_proportion,\n",
    "                                                                  target_modulations = self.target_modulations,\n",
    "                                                                  target_snrs  = self.target_snrs,\n",
    "                                                                  seed=48\n",
    "                                                                 )   \n",
    "\n",
    "        # store statistic of whole dataset\n",
    "        self.num_data = self.X_data.shape[0]\n",
    "        self.num_lbl = len(self.target_modulations)\n",
    "        self.num_snr = self.target_snrs.shape[0]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x,y,z = self.X_data[idx], self.Y_data[idx], self.Z_data[idx]\n",
    "        x,y,z = torch.Tensor(x).transpose(0, 1) , y , z\n",
    "        return x,y,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06e1df8-d275-4dc4-8dd7-b945e6b8e85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = RadioML18Dataset(mode='test')\n",
    "data_len = ds.num_data\n",
    "n_labels=ds.num_lbl\n",
    "n_snrs = ds.num_snr\n",
    "frame_size=ds.X.shape[1]\n",
    "\n",
    "del ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ef9a09-bd54-45ae-99fe-961dfb30257a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "st = time.time()\n",
    "train_dl = DataLoader(dataset=RadioML18Dataset(mode='train'),batch_size=64, shuffle=True, drop_last=True)\n",
    "valid_dl = DataLoader(dataset=RadioML18Dataset(mode='train'),batch_size=128, shuffle=False, drop_last=False)\n",
    "test_dl = DataLoader(dataset=RadioML18Dataset(mode='test'),batch_size=128, shuffle=False, drop_last=False)\n",
    "et = time.time()\n",
    "elapsed_time = et - st\n",
    "print('Execution time:', elapsed_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3bd71b-8687-4b47-852f-b093dcb87f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Block(nn.Module):\n",
    "    def __init__(self,input_shape,output_shape):\n",
    "        super().__init__()\n",
    "        self.net=nn.Sequential(\n",
    "        nn.Conv1d(input_shape, output_shape, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm1d(output_shape),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool1d(kernel_size= 2, stride= 2),\n",
    "        nn.Dropout(0.25),\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "    \n",
    "class CNN_NET(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone=nn.Sequential(\n",
    "        CNN_Block(2,24),\n",
    "        CNN_Block(24,24),\n",
    "        CNN_Block(24,48),\n",
    "        CNN_Block(48,48), \n",
    "        )\n",
    "        self.classifier=nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3072,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(128,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,n_labels)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.classifier(self.backbone(x))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2ed631-a963-47ea-89ec-9c0a959970ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,verbose=True,device='cuda',num_epoch=30):\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    train_loss = torch.zeros(num_epoch)\n",
    "    train_acc = torch.zeros(num_epoch)\n",
    "    val_loss = torch.zeros(num_epoch)\n",
    "    val_acc = torch.zeros(num_epoch)\n",
    "    \n",
    "    lr = 1e-4\n",
    "    optimizer = optim.Adam(list(model.parameters()), lr=lr)\n",
    "    lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer , 0.9 )\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    \n",
    "    for epoch in trange(num_epoch, unit='epochs'):    \n",
    "        #Trainning phase\n",
    "        model.train()\n",
    "        for x,y,z in train_dl:\n",
    "            # TODO\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss[epoch] += loss.detach().cpu()\n",
    "            train_acc[epoch] += torch.mean((torch.argmax(logits.to('cpu'), dim=-1) == y.to('cpu')).float())\n",
    "        #Evaluation phase\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x,y,z in valid_dl:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                logits = model(x)\n",
    "                loss = criterion(logits,y)\n",
    "                val_loss[epoch] += loss.detach().cpu()\n",
    "                val_acc[epoch] += torch.mean((torch.argmax(logits.to('cpu'), dim=-1) == y.to('cpu')).float())\n",
    "        lr_scheduler.step()\n",
    "        train_loss[epoch] /= (len(train_dl.dataset) // train_dl.batch_size)\n",
    "        train_acc[epoch] /= (len(train_dl.dataset) // train_dl.batch_size)\n",
    "        val_loss[epoch] /= (len(valid_dl.dataset)//valid_dl.batch_size)\n",
    "        val_acc[epoch] /= (len(valid_dl.dataset)//valid_dl.batch_size)\n",
    "        if verbose:\n",
    "            tqdm.write('Epoch {} (train) -- loss: {:.4f} accuracy: {:.4f}'.format(epoch, train_loss[epoch], train_acc[epoch]))\n",
    "            tqdm.write('Epoch {} (valid) -- loss: {:.4f} accuracy: {:.4f}'.format(epoch, val_loss[epoch], val_acc[epoch]))\n",
    "    return model,[train_loss,train_acc,val_loss,val_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85aad5f5-48bb-4e94-9505-63e9c4add887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, device='cuda'):\n",
    "    model.eval()\n",
    "    Y_pred_ = []  # Predictions\n",
    "    Y_true_ = []  # Ground truth\n",
    "    Z_snr_ = []   # SNR values\n",
    "    \n",
    "    target_classes = test_dl.dataset.target_modulations\n",
    "    target_snrs = test_dl.dataset.target_snrs\n",
    "    modulation_classes = test_dl.dataset.modulation_classes\n",
    "    target_modulations_indices = [modulation_classes.index(mod) for mod in target_classes]\n",
    "    \n",
    "    # Initialize accuracy stats DataFrame\n",
    "    accuracy_stats = pd.DataFrame(\n",
    "        0.0,\n",
    "        index=target_classes,\n",
    "        columns=target_snrs.astype('str'))\n",
    "    \n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        for x, y, z in test_dl:\n",
    "            # Move tensors to specified device\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            z = z.to(device)\n",
    "            \n",
    "            # Get model predictions on device\n",
    "            logits = model(x)\n",
    "            y_pred = torch.argmax(logits, dim=-1)\n",
    "            \n",
    "            # Store results\n",
    "            Y_pred_.append(y_pred.cpu())  # Move back to CPU for storage\n",
    "            Y_true_.append(y.cpu())\n",
    "            Z_snr_.append(z.cpu())\n",
    "    \n",
    "    # Convert to numpy for easier processing\n",
    "    Y_pred = torch.cat(Y_pred_).numpy()\n",
    "    Y_true = torch.cat(Y_true_).numpy()\n",
    "    Z_snr = torch.cat(Z_snr_).numpy()\n",
    "    \n",
    "    # Calculate overall accuracy\n",
    "    correct_preds = (Y_pred == Y_true).sum()\n",
    "    total_samples = len(Y_true)\n",
    "    total_accuracy = round(correct_preds * 100 / total_samples, 2)\n",
    "    print(f'Accuracy on test dataset: {total_accuracy}%')\n",
    "    \n",
    "    # Map indices back to original modulation classes if needed\n",
    "    for index, value in enumerate(target_modulations_indices):\n",
    "        Y_pred[Y_pred == index] = value\n",
    "        Y_true[Y_true == index] = value\n",
    "    \n",
    "    # Calculate accuracy per modulation and SNR\n",
    "    for modu in target_modulations_indices:\n",
    "        mod_class = modulation_classes[modu]\n",
    "        for snr in target_snrs:\n",
    "            snr_str = str(snr)\n",
    "            \n",
    "            # Find samples for this modulation and SNR\n",
    "            mask = (Y_true == modu) & (Z_snr == snr)\n",
    "            total_samples = mask.sum()\n",
    "            \n",
    "            if total_samples > 0:\n",
    "                # Count correct predictions\n",
    "                correct_samples = ((Y_pred == Y_true) & mask).sum()\n",
    "                \n",
    "                # Calculate and store accuracy percentage\n",
    "                accuracy = (correct_samples * 100 / total_samples)\n",
    "                accuracy_stats.loc[mod_class, snr_str] = round(accuracy, 2)\n",
    "    \n",
    "    return accuracy_stats\n",
    "\n",
    "def plot_training_history(model_name:str, history:list):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(f'Training of {model_name} model on radioml2018')\n",
    "    plt.xlabel('Epochs')   \n",
    "    plt.plot(history[0], label='train_loss')\n",
    "    plt.plot(history[1], label='train_accuracy')\n",
    "    plt.plot(history[2], label='valid_loss')\n",
    "    plt.plot(history[3], label='valid_accuracy')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()\n",
    "    \n",
    "def plot_test_accuracy(model, device='cuda'):\n",
    "    accuracy_df = test_model(model, device)\n",
    "    \n",
    "    fig, axes = plt.subplots(len(test_dl.dataset.target_modulations), 1, figsize=(12, 8), sharex=True, sharey=True)\n",
    "    fig.subplots_adjust(hspace=0.4)\n",
    "    fig.supylabel('Accuracy (%)')\n",
    "    fig.supxlabel('Signal to noise ratios (dB)')\n",
    "    \n",
    "    # Handle the case where there's only one modulation\n",
    "    if len(test_dl.dataset.target_modulations) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for index, ax in enumerate(axes):\n",
    "        ax.set_title(accuracy_df.index[index])\n",
    "        ax.bar(accuracy_df.iloc[index].index, accuracy_df.iloc[index].values)\n",
    "        ax.set_ylim(0, 100)  # Set y-axis from 0 to 100%\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return accuracy_df  # Return the DataFrame for potential further analysis\n",
    "\n",
    "def train_test_plots(model, model_name, verbose=False, device='cuda', num_epoch=30):\n",
    "    model, train_history = train_model(model, verbose=verbose, device=device, num_epoch=num_epoch)\n",
    "    torch.save(model, f'{model_name}.pth')\n",
    "    plot_training_history(model_name, train_history)\n",
    "    accuracy_results = plot_test_accuracy(model, device)\n",
    "    del model\n",
    "    return train_history, accuracy_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448eaeed-1735-42e5-83f8-24a746d237bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_plots(model,model_name,verbose=False,device='cuda',num_epoch=30):\n",
    "    model, train_history = train_model(model,verbose=verbose,device=device,num_epoch=num_epoch)\n",
    "    torch.save(model,f'{model_name}.pth')\n",
    "    plot_training_history(model_name,train_history)\n",
    "    plot_test_accuracy(model)\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02acf320-621b-4353-b675-c10ef4eae09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_plots(CNN_NET(),'CNN_NET',verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5de2edd-bc8a-4b2f-a6b7-b04facf3ae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def test_model_with_improved_plots(model, device='cuda'):\n",
    "    \"\"\"\n",
    "    Enhanced version of test_model that properly tracks all modulations\n",
    "    and produces better visualizations\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    Y_pred_ = []  # Predictions\n",
    "    Y_true_ = []  # Ground truth\n",
    "    Z_snr_ = []   # SNR values\n",
    "    \n",
    "    test_dl.dataset.target_modulations\n",
    "    target_classes = test_dl.dataset.target_modulations\n",
    "    target_snrs = test_dl.dataset.target_snrs\n",
    "    modulation_classes = test_dl.dataset.modulation_classes\n",
    "    \n",
    "    # Print debug info about target modulations\n",
    "    print(f\"Target modulations: {target_classes}\")\n",
    "    print(f\"Target SNRs: {target_snrs}\")\n",
    "    \n",
    "    # Initialize accuracy stats DataFrame\n",
    "    accuracy_stats = pd.DataFrame(\n",
    "        0.0,\n",
    "        index=target_classes,\n",
    "        columns=target_snrs.astype('str'))\n",
    "    \n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        for x, y, z in test_dl:\n",
    "            # Move tensors to specified device\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            z = z.to(device)\n",
    "            \n",
    "            # Get model predictions on device\n",
    "            logits = model(x)\n",
    "            y_pred = torch.argmax(logits, dim=-1)\n",
    "            \n",
    "            # Store results\n",
    "            Y_pred_.append(y_pred.cpu())  # Move back to CPU for storage\n",
    "            Y_true_.append(y.cpu())\n",
    "            Z_snr_.append(z.cpu())\n",
    "    \n",
    "    # Convert to numpy for easier processing\n",
    "    Y_pred = torch.cat(Y_pred_).numpy()\n",
    "    Y_true = torch.cat(Y_true_).numpy()\n",
    "    Z_snr = torch.cat(Z_snr_).numpy()\n",
    "    \n",
    "    # Calculate overall accuracy\n",
    "    correct_preds = (Y_pred == Y_true).sum()\n",
    "    total_samples = len(Y_true)\n",
    "    total_accuracy = round(correct_preds * 100 / total_samples, 2)\n",
    "    print(f'Overall accuracy on test dataset: {total_accuracy}%')\n",
    "    \n",
    "    # Count samples for each modulation type\n",
    "    mod_counts = {}\n",
    "    for mod_idx, mod_name in enumerate(target_classes):\n",
    "        count = np.sum(Y_true == mod_idx)\n",
    "        mod_counts[mod_name] = count\n",
    "        print(f\"Modulation {mod_name}: {count} test samples\")\n",
    "    \n",
    "    # Calculate accuracy per modulation and SNR\n",
    "    for mod_idx, mod_name in enumerate(target_classes):\n",
    "        for snr_idx, snr in enumerate(target_snrs):\n",
    "            snr_str = str(snr)\n",
    "            \n",
    "            # Find samples for this modulation and SNR\n",
    "            mask = (Y_true == mod_idx) & (Z_snr == snr)\n",
    "            total_samples = mask.sum()\n",
    "            \n",
    "            if total_samples > 0:\n",
    "                # Count correct predictions\n",
    "                correct_samples = ((Y_pred == Y_true) & mask).sum()\n",
    "                \n",
    "                # Calculate and store accuracy percentage\n",
    "                accuracy = (correct_samples * 100 / total_samples)\n",
    "                accuracy_stats.loc[mod_name, snr_str] = round(accuracy, 2)\n",
    "            else:\n",
    "                # Mark as NaN if there are no samples\n",
    "                accuracy_stats.loc[mod_name, snr_str] = np.nan\n",
    "                print(f\"Warning: No samples for {mod_name} at SNR={snr}\")\n",
    "    \n",
    "    return accuracy_stats\n",
    "\n",
    "def plot_improved_test_accuracy(model, device='cuda'):\n",
    "    \"\"\"\n",
    "    Enhanced plotting function that shows all modulations properly\n",
    "    \"\"\"\n",
    "    accuracy_df = test_model_with_improved_plots(model, device)\n",
    "    \n",
    "    # 1. Single plot with all modulation types\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Convert to long format for seaborn\n",
    "    accuracy_long = accuracy_df.reset_index().melt(\n",
    "        id_vars=['index'], \n",
    "        var_name='SNR', \n",
    "        value_name='Accuracy'\n",
    "    )\n",
    "    accuracy_long.columns = ['Modulation', 'SNR', 'Accuracy']\n",
    "    \n",
    "    # Convert SNR to numeric for proper ordering\n",
    "    accuracy_long['SNR'] = accuracy_long['SNR'].astype(float)\n",
    "    \n",
    "    # Plot all modulations\n",
    "    sns.lineplot(\n",
    "        data=accuracy_long, \n",
    "        x='SNR', \n",
    "        y='Accuracy', \n",
    "        hue='Modulation',\n",
    "        marker='o',\n",
    "        markersize=8,\n",
    "        linewidth=2\n",
    "    )\n",
    "    \n",
    "    # Specifically highlight PSK modulations\n",
    "    psk_mods = [mod for mod in accuracy_df.index if 'PSK' in mod]\n",
    "    if psk_mods:\n",
    "        print(f\"Highlighting PSK modulations: {psk_mods}\")\n",
    "        psk_df = accuracy_long[accuracy_long['Modulation'].isin(psk_mods)]\n",
    "        \n",
    "        # Use a separate plot command with larger linewidth to highlight PSK\n",
    "        for mod in psk_mods:\n",
    "            mod_data = psk_df[psk_df['Modulation'] == mod]\n",
    "            plt.plot(mod_data['SNR'], mod_data['Accuracy'], \n",
    "                     linewidth=3.5, \n",
    "                     linestyle='--',\n",
    "                     marker='*', \n",
    "                     markersize=12)\n",
    "    \n",
    "    plt.title('Classification Accuracy vs SNR for Different Modulation Types', fontsize=16)\n",
    "    plt.xlabel('Signal-to-Noise Ratio (dB)', fontsize=14)\n",
    "    plt.ylabel('Accuracy (%)', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('all_modulations_accuracy.png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. Individual subplots for each modulation\n",
    "    # Find how many rows we need (assuming 3 plots per row)\n",
    "    n_rows = (len(accuracy_df.index) + 2) // 3  # Ceiling division\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, 3, figsize=(18, n_rows*4), sharey=True)\n",
    "    axes = axes.flatten()  # Flatten to make indexing easier\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(len(accuracy_df.index), len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    # Plot each modulation in its own subplot\n",
    "    for i, mod in enumerate(accuracy_df.index):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Get data for this modulation\n",
    "        mod_data = accuracy_df.loc[mod].astype(float)\n",
    "        \n",
    "        # Plot bar chart\n",
    "        ax.bar(mod_data.index, mod_data.values, color='skyblue' if 'PSK' not in mod else 'red')\n",
    "        \n",
    "        # Add line for trend\n",
    "        ax.plot(mod_data.index, mod_data.values, 'k--', linewidth=2)\n",
    "        \n",
    "        # Styling\n",
    "        ax.set_title(f'{mod}', fontsize=14)\n",
    "        ax.set_xlabel('SNR (dB)' if i >= len(accuracy_df.index) - 3 else '')\n",
    "        ax.set_ylabel('Accuracy (%)' if i % 3 == 0 else '')\n",
    "        ax.set_ylim(0, 105)  # Set y-axis from 0 to 100% with a bit of margin\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Rotate x-axis labels for better readability\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45)\n",
    "    \n",
    "    plt.suptitle('Classification Accuracy by Modulation Type', fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.95)  # Make room for suptitle\n",
    "    plt.savefig('modulation_accuracy_subplots.png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Also create a heatmap visualization\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sns.heatmap(accuracy_df.astype(float), annot=True, cmap='viridis', fmt='.1f', \n",
    "                cbar_kws={'label': 'Accuracy (%)'})\n",
    "    plt.title('Classification Accuracy Heatmap by Modulation and SNR', fontsize=16)\n",
    "    plt.xlabel('Signal-to-Noise Ratio (dB)', fontsize=14)\n",
    "    plt.ylabel('Modulation Type', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('modulation_accuracy_heatmap.png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    return accuracy_df\n",
    "\n",
    "\n",
    "def check_dataset_distribution(test_dl):\n",
    "    \"\"\"\n",
    "    Analyze the distribution of modulations in the dataset\n",
    "    \"\"\"\n",
    "    # Get dataset\n",
    "    dataset = test_dl.dataset\n",
    "    \n",
    "    # Analyze distribution\n",
    "    mod_counts = {}\n",
    "    snr_mod_counts = {}\n",
    "    \n",
    "    # Initialize counts for all modulations\n",
    "    for mod in dataset.target_modulations:\n",
    "        mod_counts[mod] = 0\n",
    "    \n",
    "    # Count occurrences of each modulation\n",
    "    for i in range(len(dataset)):\n",
    "        _, mod_idx, snr = dataset[i]\n",
    "        mod = dataset.target_modulations[mod_idx]\n",
    "        \n",
    "        # Count by modulation\n",
    "        mod_counts[mod] += 1\n",
    "        \n",
    "        # Count by modulation and SNR\n",
    "        if snr not in snr_mod_counts:\n",
    "            snr_mod_counts[snr] = {}\n",
    "        if mod not in snr_mod_counts[snr]:\n",
    "            snr_mod_counts[snr][mod] = 0\n",
    "        snr_mod_counts[snr][mod] += 1\n",
    "    \n",
    "    print(\"Modulation distribution in dataset:\")\n",
    "    for mod, count in mod_counts.items():\n",
    "        print(f\"  {mod}: {count} samples\")\n",
    "    \n",
    "    # Special check for PSK modulations\n",
    "    psk_mods = [mod for mod in dataset.target_modulations if 'PSK' in mod]\n",
    "    print(\"\\nPSK modulation distribution:\")\n",
    "    for mod in psk_mods:\n",
    "        print(f\"\\n{mod} distribution across SNRs:\")\n",
    "        for snr in sorted(snr_mod_counts.keys()):\n",
    "            count = snr_mod_counts[snr].get(mod, 0)\n",
    "            print(f\"  SNR {snr}dB: {count} samples\")\n",
    "    \n",
    "    return mod_counts, snr_mod_counts\n",
    "\n",
    "\n",
    "# Enhanced version of train_test_plots that includes improved plotting\n",
    "def improved_train_test_plots(model, model_name, verbose=False, device='cuda', num_epoch=30):\n",
    "    # First check the dataset distribution\n",
    "    print(\"Analyzing test dataset distribution...\")\n",
    "    mod_counts, snr_mod_counts = check_dataset_distribution(test_dl)\n",
    "    \n",
    "    # Train the model\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    model, train_history = train_model(model, verbose=verbose, device=device, num_epoch=num_epoch)\n",
    "    torch.save(model, f'{model_name}.pth')\n",
    "    \n",
    "    # Plot training history\n",
    "    plot_training_history(model_name, train_history)\n",
    "    \n",
    "    # Plot test accuracy with improved visualization\n",
    "    print(\"\\nEvaluating and plotting test accuracy...\")\n",
    "    accuracy_results = plot_improved_test_accuracy(model, device)\n",
    "    \n",
    "    return model, train_history, accuracy_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GNU Radio ai_sdr)",
   "language": "python",
   "name": "ai_sdr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
